<search><entry><title>php set_time_limit函数不起作用原因解析</title><url>https://d-j.fun/post/notes/2022/0508_php_set_time_out_not_work/</url><categories><category>notes</category></categories><tags/><content type="html"> 作为phper这么多年，很多时间都花在业务、框架上，反而一些细节不经意的就抽自己一巴掌。本文解析set_time_limit配置，以及相关细节。也记录一下此次掉坑经历，给自己以后指一个方向。
起因 服务器某个接口相应时间长达100s，而且报nginx 502错误。检查发现php max_execution_time使用的默认值30s。错误分析：502 gateway错误，可以定位到是php脚本处理太慢造成的。但是让人怀疑的是为什么30s脚本不停止。
解析 官方解释 The set_time_limit() function and the configuration directive max_execution_time only affect the execution time of the script itself. Any time spent on activity that happens outside the execution of the script such as system calls using system(), stream operations, database queries, etc. is not included when determining the maximum time that the script has been running. This is not true on Windows where the measured time is real. 翻阅官方文档得到答案：该配置项仅仅代表脚本本身的执行时间，而不包括系统调用、流操作、数据库查询所占用的时间（即不计算 sleep,file_get_contents,shell_exec,mysql_query等花费的时间）。
起因中提到的问题就找到原因了：脚本本身查询mysql耗费了太久时间，导致达到nginx proxy_read_timeout 100时间限制。nginx在发现proxy即fpm没有在规定时间内返回结果，就直接返回调用方502错误。
自我验证 &amp;lt;?php error_reporting(0); ini_set(&amp;#39;display_errors&amp;#39;, &amp;#39;off&amp;#39;); // set_error_handler 不能捕获致命错误 register_shutdown_function(function () { echo sprintf(&amp;#34;脚本结束时间%f\n&amp;#34;, microtime(true)); }); echo sprintf(&amp;#34;脚本开始时间%f\n&amp;#34;, microtime(true)); for($i=0;$i&amp;lt;100000000;$i++){ sha1(time()); } echo sprintf(&amp;#34;第一次循环结束时间%f\n&amp;#34;, microtime(true)); set_time_limit(10); $i = 0; while ($i &amp;lt;= 10) { echo &amp;#34;i=$i&amp;#34;; sleep(2); $i++; } $end = microtime(true); var_dump(getrusage()); echo sprintf(&amp;#34;\n第二次循环结束时间%f\n&amp;#34;, microtime(true)); while (true) { sha1(time()); } echo sprintf(&amp;#34;\n第三次循环结束时间%f\n&amp;#34;, microtime(true)); // output //脚本开始时间1651993104.293944 //第一次循环结束时间1651993191.067107 //i=0 i=1 i=2 i=3 i=4 i=5 i=6 i=7 i=8 i=9 i=10 //第二次循环结束时间1651993213.096094 //脚本结束时间1651993223.126825 第一次循环占用时间 86.77s (时间1) 第二次循环占用时间 22.02s (时间2) 第三次循环占用时间 10.03s (时间3) 脚本解析：
时间1是在set_time_limit执行前的脚本执行时间，说明set_time_limit执行的时候，时间计数器从0重新计数 时间2是因为sleep了11次，每次2s。说明循环本身只是占用了0.02s 时间3是set_time_limit开始到脚本Fatal Error退出执行之间的时间。虽然第二次循环占用了22s，但是sleep不被计数。 设置真实执行时间 &amp;lt;?php echo sprintf(&amp;#34;脚本开始时间%f\n&amp;#34;, microtime(true)); pcntl_async_signals(1); pcntl_signal(SIGALRM, function () { echo sprintf(&amp;#34;脚本结束时间%f\n&amp;#34;, microtime(true)); exit(&amp;#39;Stop it!&amp;#39;); }); pcntl_alarm(3); $i = 0; while (true) { $i++; sha1(time()); echo &amp;#34;i = {$i}\n&amp;#34;; } echo sprintf(&amp;#34;脚本结束时间2%f\n&amp;#34;, microtime(true)); // output 脚本开始时间1651994735.305631 i=33万次... 脚本结束时间1651994738.307060 Stop it! 或者使用fork调用，父进程监控子进程运行。
$pid=pcntl_fork(); if ($pid) { while (true) { shell_exec(&amp;#39;sleep 10&amp;amp;&amp;#39;); } } else { sleep(5); posix_kill(posix_getppid(),SIGKILL); } 如果是CLI脚本，有更多解决方案：
timeout 5 /usr/bin/php -q /path/to/script 总结 不建议使用set_time_limit(0), 因为脚本会一直执行下去，影响服务器负载 脚本默认max_execution_time为0，即会一直执行下去，建议设置该配置，因为脚本会永久占用进程。 set_time_limit 会重置时间计数。比如在脚本已经运行20s的时候调用set_time_limit(10),那么脚本执行时间为30s。如果运行一个耗时任务的时候，一般放在脚本第一行。 sleep,file_get_contents,shell_exec,mysql_query这些函数包含在设置的时限内，所以这些函数本身执行时间应该自己考虑在内，不要让时间浪费在没必要的事情上。 set_time_limit 不能使用在安全模式下。set_time_limit() [function.set-time-limit]: Cannot set time limit in safe mode</content></entry><entry><title>使用jenkins pipeline部署Gcloud Function</title><url>https://d-j.fun/post/notes/2022/0506_jenkins_pipeline_deploy_gcloud_function/</url><categories><category>notes</category></categories><tags/><content type="html"> Google Cloud Function、aws lambda都是类似的无服务器服务，一种轻量级计算解决方案，通过相应平台封装的对应事件，返回响应。无需管理服务器、并且可以根据负载量自动扩缩容，这些特点特别方便我们一些高负载的需求。
但是代码部署方式上，和在服务器上自主搭建服务是有差别的：gcf接受Cloud Source Repositories（google的代码库平台）、zip文件；aws lambda 接受编译好的二进制文件的压缩包。不过aws 和 gcloud 都提供了强大的命令行工具，配合jenkins部署是一个不错的选择。由于gcloud、aws机制类似，本文以gcloud为例。
Google Cloud Function 部署 代码载体选择 google cloud function支持四种：
内嵌编辑器： 只适合一些简单的测试 zip文件上传：将zip打包比较适合jenkins，jenkins对shell脚本支持的比较好，但是gcloud命令没有看到接受文件上传的选项。 cloud storage上的zip：google cloud storage对应aws的s3，将代码压缩好上传到这里还可以备份，是比较好的选择 Cloud Source Repositories：考虑到一般公司都选择自建的gitlab仓库，需要做一层同步。 通过比较几种代码载体，第三种是适合博主的方式，具体选择哪种，视你的具体场景选择。
gcloud sdk安装 安装教程见 Google CLi安装 。一般服务器linux操作系统错不了，简单整理官方文档步骤如下:
1 2 3 4 5 6 7 8 9 # 下载google cloud sdk压缩包 curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-377.0.0-linux-x86_64.tar.gz # 解压 tar -xf google-cloud-sdk-377.0.0-linux-x86.tar.gz # 执行安装sh脚本 ./google-cloud-sdk/install.sh # 由于要把代码上传到cloud storage，用到alpha组件 gcloud components install beta #接下来不要执行gcloud init，jenkins部署提供了secret file认证文件的管理，为了安全。 以上操作是在jenkins同台机器上执行。
gcloud sdk认证 首先判断是否已认证：gcloud auth list。该命令会列出已认证的账号，以及活跃账号。 google iam提供了几种认证方式，因为要在jenkins pipeline里使用，最好选择gcloud auth activate-service-account。当然也可以选择直接在jenkins机器jenkins用户下直接执行gcloud init。 即使gcloud auth activate-service-account该种方式认证，gcloud也会将私钥的副本存储在$HOME/.config/gcloud目录下面。如果要可靠的存储gcloud身份验证信息，在运行完pipeline之后，清楚一下本地缓存的密钥文件rm -rf $HOME/.config/gcloud。
另外建议创建权限足够但不多余的专门用户，服务于jenkins。权限请选择：Cloud Functions Admin、Storage Admin。 jenkins pipeline部署 pipeline介绍 jenkins pipeline 流水线是用户定义的一个cd模型，通过代码定义项目的整个构建过程，支持各种组件，灵活而强大。类似的有github runner、bitbucket pipeline以及比较通用的github actions。
pipeline { agent any stages {stage(&amp;#39;Build&amp;#39;) { steps { sh &amp;#39;make&amp;#39; }}stage(&amp;#39;Test&amp;#39;){steps {sh &amp;#39;make check&amp;#39;junit &amp;#39;reports/**/*.xml&amp;#39; }}stage(&amp;#39;Deploy&amp;#39;) {steps {sh &amp;#39;make publish&amp;#39;}}}}简单的语法定义将构建过程分成步骤stage，同时支持环境变量定义，同时jenkins还提供了pipeline-syntax片段生成器。详细参考Jenkins Pipeline文档。
添加密钥文件 在jenkins系统管理-全局凭据中，添加密钥，选择 secret file。具体可参考 []
jenkins pipeline部署Gcloud Function pipeline示例 pipeline {agent anystages {stage(&amp;#39;克隆&amp;#39;) {when {branch &amp;#39;main&amp;#39;}steps {dir(path:&amp;#34;./&amp;#34;) {checkout([$class: &amp;#39;GitSCM&amp;#39;, branches: [[name: &amp;#39;*/master&amp;#39;]], doGenerateSubmoduleConfigurations: false, userRemoteConfigs: [[credentialsId:&amp;#34;仓库git凭证&amp;#34;, url:&amp;#39;仓库地址&amp;#39;]]])}}}stage(&amp;#39;上线&amp;#39;) {when {branch &amp;#39;main&amp;#39;}steps {withCredentials([file(credentialsId: &amp;#39;gcloud secret file id&amp;#39;, variable:&amp;#39;GCP_FILE&amp;#39;)]) {sh &amp;#39;git archive -o /tmp/code.zip HEAD&amp;#39; sh &amp;#34;gcloud auth activate-service-account 账户名称 --key-file=&amp;#39;${GCP_FILE}&amp;#39;&amp;#34;sh &amp;#39;gcloud alpha storage cp /tmp/code.zip gs地址&amp;#39;sh &amp;#39;gcloud functions deploy 函数名 --source gs地址&amp;#39;}}}stage(&amp;#39;测试&amp;#39;) {steps {sh &amp;#39;curl -vvv 链接&amp;#39;}}}}触发构建，可以根据自己需要设置，例子中是main分支有更新。还可以选择手工点击构建。
可能遇到的问题 gcloud sdk not found类似问题：安装gcloud cli必须安装在jenkins所在机器 User does not have the 'iam.serviceAccounts.actAs' permission on *@appspot.gserviceaccount.com required to create the function. You can fix this by running gcloud iam service-accounts add-iam-policy-binding *@appspot.gserviceaccount.com --member=user: --role=roles/iam.serviceAccountUser&amp;quot;,详见 官方解释 ：是因为创建用户和部署用户不同，解决办法为 gcloud iam service-accounts add-iam-policy-binding 创建function用户 --member=serviceAccount:serviceaccount用户 --role=roles/iam.serviceAccountUser 总结 jenkins pipeline是一个简单而又强大的cd工具，可以从平时复杂冗余的工作中解放出来。由于对shell及jenkins本身强大的插件机制，可扩展的地方很多，本文只是拿一个具体的任务举例。目前比较可惜的是pipeline类似的功能都是在具体的平台上，没有一个更宽泛的概念，期待。。。
引用 https://cloud.google.com/sdk/gcloud/reference/functions/deploy gcloud sdk function文档 https://tech.ray247k.com/blog/202204-jenkins-cicd-3-push-docker-image-to-gcr/ Jenkins 打包 Docker image 並推送到 GCR</content></entry><entry><title>curl 关于服务时间性能的指标探究及应用</title><url>https://d-j.fun/post/notes/2022/0501_benchmark_server_latency_with_curl/</url><categories><category>notes</category></categories><tags><tag>Linux命令</tag></tags><content type="html"> 作为一个服务端开发，强烈意愿需要一个性能检测工具，而时间是性能一个重要的指标。而curl 请求输出可以根据自己需要设置（time_namelookup、time_connect、time_appconnect、time_pretransfer、time_starttransfer、time_total）时间相关的输出。但是搜索了google、baidu不止一天两天，得到的答案都是man curl，而没有一个更精准、容易理解的答案。最终无意中搜索到&amp;lt;引用&amp;gt;的文章，茅塞顿开，建议读到本篇文章的都耐心读完。
预备知识 curl标准化输出 在一个请求结束时，curl会根据-w，&amp;ndash;write-out 选项打印出来定制化信息到标准输出。format 包含有占位符的字符串，curl会替换占位符为预定义的变量的值。
比如 HTTP状态码：%{http_code} 会被替换为 HTTP状态吗: 200
时间指标官方解释 时间指标的单位都是秒，计时开始都是curl请求开始时间，也就是dns开始查询那一刻的时间。
time_namelookup：开始到dns查询完成花费时间 time_connect：开始到tcp三次握手完成花费时间 time_appconnect：开始到ssl握手时间完成花费时间 time_pretransfer: 开始到文件传输即将开始花费时间 time_starttransfer: 从开始到第一个字节即将被传输，包含time_pretransfer和服务器计算结果所需时间 time_total 整个操作所有花费时间 理解重点 一个容易被忽略的前提，curl作为一个客户端工具，计算所有时间的前提都代表着网路传输的客户端。理解每个时间，必须先提醒自己这个前提。
探究过程 请求例子 /usr/local/opt/curl/bin/curl -L -w &amp;#39;@curl.txt&amp;#39; &amp;#39;localhost:8080/a.php&amp;#39; time_namelookup: 0.002783 time_connect: 0.002928 time_appconnect: 0.000000 time_redirect: 2.104259 time_pretransfer: 0.002981 time_starttransfer: 6.177934 ---------- time_total: 6.178134 例子详情：
// a.php &amp;lt;?php sleep(2); header(&amp;#34;location:./b.php&amp;#34;); // b.php &amp;lt;?php sleep(4); time_namelookup指标 这个很好理解，dns查询时间，即curl访问某个域名的时候，需要先从dns服务器以下该域名对应的ip。这个过程一般会很快，是因为服务器在首次获取到ip的时候，会缓存结果一段时间。我在本地测试/etc/hosts解析的域名，时间保持在2～3ms左右。
time_connect指标 网络建立socket需要经历三次握手，该指标的值就是开始到建立socket成功的时间。time_connect-time_namelookup即curl和服务器建立socket所花费的时间，对应上面的例子花费了0.145ms。测试了baidu，该指标为21ms。
time_appconnect指标 真正的传输建立完socket便可以，比如http便是直接在tcp协议上传输内容。但是https为了网络内容的安全会在tcp上再次进行ssl层的建立，该阶段百度测试120ms。所以该指标也是一个很重要的查询整体性能的因子。上面的例子由于是http，故该指标值为0。
time_redirect指标 从上例子中可以看出，该指标是截止点在于跳转到b之前的瞬间。由于a文件在跳转之前先等待了2s，所以curl接收到301请求之后，由于-L（follow redirects），会立马请求b.php，但是b.php的返回是4s之后，所以该时间点，应该是接收到301之后，再次请求服务端的瞬间。
这里就牵扯到一个问题：如果header location 是其他网站，是不是要重新计算namelookup的时间，以及建立链接的时间。
// a.php &amp;lt;?php sleep(2); header(&amp;#34;location:https://www.baidu.com&amp;#34;); time_namelookup: 0.090075 time_connect: 0.158963 time_appconnect: 0.214078 time_redirect: 2.412030 time_pretransfer: 0.308881 time_starttransfer: 2.570669 ---------- time_total: 2.577325 可以看到time_namelookup、 time_connect、time_appconnect都有较大的变化，如果单独请求百度得到的三个值也会小于上面三个值。所以三个指标如果包含跳转，应该是跳转前后两次的对应加和。
该指标指最后一个请求开始的瞬间，只考虑整个链条的最后一次请求。
最困惑的time_pretransfer指标 从上面的例子可以发现该指标会比time_appconnect（https）或time_connect（http）多几十微秒，如果是跳转会多点，但是相对于网络来回来说，这个时间太小。所以有的文档说，该指标只是为了和connect概念上做区分。但是从细微的时间上的差别来看，足够cpu做很多事情，所以它表示的应该是，在connect之后处理了一些协议相关的初始化操作，然后将数据放到网卡之前的瞬间。
通俗的说，该指标结束点在于开始往服务器发送真正的http、https请求的瞬间。
time_starttransfer和time_total指标 这两个指标应该是比较好理解的。time_starttransfer 对应TTFB，即curl收到服务端传来的第一个字节的瞬间。time_total整个curl操作周期的总时间。
指标应用 dns解析快慢，直接使用time_namelookup 链接创建时间，根据http\https, 使用time_connect\time_appconnect - 直接使用time_namelookup 服务端处理时间，time_starttransfer - time_pretransfer 内容下载时间，time_total - time_starttransfer 总结 curl的几个时间指标真实反应一次请求的各个阶段，对于服务时间性能方面的测试是一个很大的助力。关于本文，主要针对无法理解curl man的解释，做了各个方面的探究。这些探究都是针对实际操作而得出的结论，可能无法真实反应curl本身源代码方面的设计。
不过针对平时的应用，参考&amp;lt;指标应用&amp;gt;小节，完全可以满足平时所用。如果针对某个具体的指标有疑问，可以深入到具体的指标实验中做对比。
引用 https://speedtestdemon.com/a-guide-to-curls-performance-metrics-how-to-analyze-a-speed-test-result/</content></entry><entry><title>Github Pages最佳实践, 基于Github Actions</title><url>https://d-j.fun/post/notes/2022/0501_github_pages_best_practices/</url><categories><category>notes</category></categories><tags><tag>Github</tag></tags><content type="html"> 搭建本博客使用到的技术是hugo结合github page，详见hugo自建博客。博客中可以看到详细过程：将hugo写作环境推到github main分支，通过github action构建到gh-pages分支。这是目前见到的大部分方案，也有通过在其他仓库（gitee）将最终结果推送到github上的。
最佳实践 个人觉得最佳的方案，应该隐藏写作环境，即hugo最终生成静态文件依赖的模板、md文件等。否则复制一个网站的成本就太小了，有心的人只需要下载你的写作环境，本地重新build以下，即可完全仿造你的整个流程。当然编译后的静态文件总归要暴露出去，但是后续更新、批量修改都增加了仿冒的成本。
针对本博客的实现方案，最佳实践应该为 main分支隐藏，gh-pages分支继续保留。
实现方案 构想过集中方案，可以根据自己情况实施：
自己有服务器的，可使用的方案很多，写作环境保留在自己服务器即可，静态文件可以存放服务器，或者推送到github pages 建立两个Github仓库（注意创建顺序），写作环境保存在私有仓库，推送到另外一个公开仓库里面 类似2，不过写作环境放在自己搭建的仓库更安全，或者国内gitee、国外aws gitcommit 我选择第二种方案测试了一下
创建私有仓库 由于Github 二级域名默认在账号级别创建的第一个仓库为根目录，具体实施应该为：
静态文件推送到账号下第一个创建的仓库 写作环境推送到账号下除第一个创建仓库以外的仓库 我的做法：将第一个仓库的内容删除，然后本地git remote add origin 第二个仓库地址
构建实现 peaceiris/actions-gh-pages 该该组件是编译好的静态文件推送到Github Pages，集成于Github Actions。详细见 hugo自建博客 Github Actions yaml文件。
- name:Deploy# 部署uses:peaceiris/actions-gh-pages@v3with:personal_token:${{ secrets.PERSONAL_TOKEN }}publish_dir:./publiccname:www.d-j.funexternal_repository:micywin/hugo-dj注意yaml和原文章的区别，由于原文章是将构建好的静态文件推送到当前仓库的gh-pages分支，直接使用Github Actions初始化的Github_TOKEN即可，但是如果跨仓库，甚至于不通的仓库提供商，那么这里就要设置为对应的token。由于博主使用的是github的另外一个仓库，使用personal_token即满足需求。
按照上图设置好secrect之后，注意external_repository，这里是设置相对于当前仓库的另外一个仓库。
这样设置好之后，重新推送一下写作环境的代码到第二个仓库，那么没有问题情况下，第一个仓库的gp-pages分支会出现最新一版的静态文件。
拓展内容 关于peaceiris/actions-gh-pages该组件还有更多的配置选项，可以根据自己需要去配置，个人觉得比较有用的：
设置full_commit_message, 让每次更新可以看到提交的相关信息 如果不想部署的时候影响到在线阅读体验，可以定时在半夜部署 等，可以根据自己情况去配置。博主的Deploy的完整配置：
- name:Deployuses:peaceiris/actions-gh-pages@v3with:personal_token:${{ secrets.PERSONAL_TOKEN }}publish_dir:./publiccname:www.d-j.funexternal_repository:micywin/hugo-djfull_commit_message:${{ github.event.head_commit.message }}总结 为了写作体验，和后续可能的问题，应该提前做好各种规划。比如本文提到的写作环境隐藏、自动给图片添加水印、还有目录的规划、文章分类的划分等。</content></entry><entry><title>使用hugo在github上搭建独立博客</title><url>https://d-j.fun/post/technical/2022/0426_hugo_hosted_on_github/</url><categories><category>technical</category></categories><tags><tag>Github</tag><tag>Hugo</tag></tags><content type="html"> hugo golang编写的静态化网站构建工具，速度、灵活是两个标榜的特点。选择该工具的原因：有自己喜欢的模版、方便的自定义、快速的调试，最关键是可以git版本化管理内容，不用依托于mysql，这是最关键的原因。
github pages更是提供了免费的托管，同时github actions提供自动化编译，搭配起来是完美。
纵览搭建过程 Hugo 在本地初始化git仓库，在该仓库中搭建hugo环境，主要是选择自己喜欢的模板 Hugo 主题 。接下来比较耗费时间的是，根据自己需要修改模板：比如title、description，还有一些样式，很多没有定义在配置里，就需要自己在layouts中找到对应的文件进行修改，不过hugo的文件结构比较清晰，有过网站开发经验的很容易找到规律。
Github 本地准备完毕后便可以将整个hugo环境推到github，然后利用github actions自动化构建，便完成基础搭建。 hugo官方提供的有github actions yml文件，可以根据自己需要改动。
一般的流程是：
拉取代码 hugo编译 代码推送到gh-pages分支 最终在github仓库的设置里，将pages分支设置为gh-pages，便可以通过【github username】.github.io网址，看到自己的博客雏形了。
详细搭建过程 本小节除了给出一些必要的安装步骤，还会推荐一些工具搭配，除了有利于搭建过程、对以后博客坚持写作也有帮助。同时一些安装过程中踩到的坑，也会在具体步骤中标注。
Hugo环境 官网给出了无比详细的、各个平台的安装步骤 Hugo 安装 , 直接选择自己的操作系统，一步步安装即可。由于博主开发机是mac pro，直接一步到位 brew install hugo
打开 terminal (推荐安装iTerm2), 输入hugo version, 如果输出hugo版本，代表安装成功，并正确配置了执行路径。如果提示找不到命令，原因可能是 hugo执行程序不在环境变量PATH中，将程序放到PATH路径中，一般是bin、/user/bin等，或者执行export PATH=&amp;quot;$PATH:hugo安装路径&amp;quot;，再次执行hugo version。一般的问题都出在这里，如果不符合自己的情况，可以再仔细阅读官方安装文档，或者通过评论联系博主。
新建网站：hugo new site [eight]。该命令会在执行命令的当前路径，新建eight文件夹，目录中比较重要的有themes目录, config.toml。执行完命令，用一款编辑器打开目录，熟悉一下目录结构，毕竟以后写博客都要面对这些目录。推荐安装sublime，博主开发环境都选择idea，随意选择了goland。无论选择什么编辑器，方便的文件管理、目录结构、markdown编辑预览功能是必须具备的。工具一定要选择一个适合自己，功能方便的，涉及到自己的写作体验。
Hugo主题 hugo主题选择，个人喜好问题，不过不建议花太多时间在这上面，毕竟搭建博客是为了记录、分享内容（虽然博主纠结了好久，最终选择了next）。
hugo主题安装三种选择，不同的选择，各有优劣，视自己具体情况而定：
git submodules: git submodule add 主题仓库地址 themes/主题名称，该方法适合于以后完全不会自己修改模板的人，好处是如果模板主题作者修改了模板，还可以随时更新到最新。但是如果想自定制一些功能，就得去原作者仓库提交pr。 将文件复制到themes目录：在其他目录下载完themes文件，将文件夹复制到themes目录下，随着你的git仓库一块提交，相当于在你的仓库里增加文件内容。这样你可以随意修改模板、样式，但是相对于根目录来说，themes有很多部分是重合的，如果是极度洁癖慎用。 将模板对应的文件夹，覆盖根目录对应文件：该方法具有第二种方法的随意修改的有点，而且文件也不会出现冗余，博主选择该方法。 执行hugo server，在命令提示中可以看到 localhost:1313 (如果你在另外一个地方执行过了，可能是其他端口)，将该地址复制到浏览器地址栏，点击访问，便可以实时预览自己的博客。如果你修改了博客中的模板、样式、文章等，保存后便可以在这个地址看到。
这个时候，便可以修改logo、博客名称、博客描述，最好加一篇文章方便调试。
Github Pages部署 上面步骤好了之后，便可以部署github pages了。注意一点：一个github账号，只有一个github.io的域名（【github username】.github.io），如果不是规划该账号下，多个项目对应一个域名，那么建议新建一个github账号。
假设你的账号用户名 eight（小八），那么可以新建一个public仓库eight.github.io (这样命名，github会默认开启pages功能，不过不强求)，copy仓库地址。然后在本地仓库执行git remote add origin 仓库地址，然后将代码推送到GitHub仓库。有一个点，github主分支默认是main，本地一般都是master。具体用哪个自己偏好决定。
在项目根目录添加.github/workflows/gh-pages.yml文件：
name:github pages# 任务名称on:push:branches:- main# 触发分支jobs:deploy:runs-on:ubuntu-20.04# 任务执行环境steps:# 每个步骤：name 步骤名称，uses 使用组件，with 参数- name:Check out repository code# 下载代码uses:actions/checkout@v2with:submodules:true- name:Setup Hugo# 下载hugouses:peaceiris/actions-hugo@v2with:hugo-version:&amp;#39;latest&amp;#39;## extended: true- name:ls# 最好加这一步，要不然报错都不知道为啥，查看工作空间文件run:ls ${{ github.workspace }}/themes/hugo-theme-next2/- name:Build# 构建run:hugo --minify- name:Deploy# 部署uses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.GITHUB_TOKEN }}publish_dir:./publiccname:www.d-j.fun推送到github之后，会自动按照这个yaml文件的脚本执行，注意分支名字，如果不对，该workflows不会执行。如果没有执行成功，点击github 仓库的actions按钮，然后找到具体的action，点开可以查看详细log记录。成功后仓库会多一个gh-pages分支。
特别需要注意：cname文件，如果要使用自定义的域名，cname参数会使 peaceiris/actions-gh-pages@v3 添加一个cname，cname文件如果缺失，会造成github仓库设置里面的自定义域名丢失lost。。。
后续操作 这个时候访问eight.github.io，便可以看到自己的博客。 不同的模板需要的配置不一样，还需要稍微的微调。如果想自定义域名，点击github仓库的设置，找到pages，在custom domain填入自己的域名。有个先提条件，需要将域名cname到eight.github.io。
Hugo自建博客总结 整个过程步骤不多，但是小细节很多。比较耗费时间的是下载主题总归会有需要修改的地方，这个比较耗费时间。还有应该着重在内容上，不要太纠结于一些界面上的瑕疵。一定要选择自己满意的编辑器，特别是修改layouts布局文件的时候，以及发布文章。否则会被一些格式上面的问题困扰。
感谢 本博客搭建参考了 兰陵子 的搭建过程，也参考了 凡梦星尘 的优化笔记 。</content></entry></search>