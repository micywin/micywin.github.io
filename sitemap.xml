<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Laravel FileSystem源码分析</title><url>https://d-j.fun/post/technical/2022/0626_laravel_filesystem_source_analysis/</url><categories><category>technical</category></categories><tags><tag>laravel</tag></tags><content type="html"> Facade 入手 Laravel Facade模式实现方式是：所有的Facade（比如Storage）都需要继承虚拟类Facade。虚拟类Facade提供了一个__callStatic方法，来承接所有的方法调用。
该方法提供的作用包括：
获取具体Facade对应的实例。子类实现的getFacadeAccessor方法提供 调用实例对应方法。__callStatic方法参数提供。 而Storage Facade对应的实例是FilesystemManager对象，是通过FilesystemServiceProvider注册到容器里面的。
适配器 Laravel在多处地方使用到适配器，比如 database, auth, filesystem。不同适配器都会对应一个Manager后缀的管理器，比如FilesystemManager对应着filesystem。
管理器主要功能：
创建不同的driver 注册新driver 获取driver Storage通过调用disk（或drive、cloud对应配置filesystems.cloud），获取（如果不存在创建）对应driver实例。
如果想实现自己的driver，可以通过FilesystemManager的extend方法，比如你想使用aliyun oss云存储，那么可以
$this-&amp;gt;app-&amp;gt;make(&amp;#39;filesystem&amp;#39;)-&amp;gt;extend(&amp;#39;aliyun&amp;#39;, function ($app, array $config) { // 返回根据config创建的实例即可 }); 如果返回的实例实现了League\Flysystem\FilesystemInterface接口，那么就使用FilesystemAdapter统一包装一下，如果没有，直接返回driver实例，给调用方。而所谓的包装，大部分作用是为了和laravel本身的调用接口进行统一，做了一层代理转发。如果driver本身实例存在FilesystemAdapter没有的方法，还是会溯源调用driver方法。
如果想实现自己的driver，那这里的driver对应的不应该是aliyun官方client实例，而应该实现自己的adapter做一层适配。
调用举例 本身存在方法 getTemporaryUrl Storage Facade调用disk方法，获取到driver实例 driver实例满足FilesystemInterface，被FilesystemAdapter包装 FilesystemAdapter中的方法temporaryUrl，接受调用 调用driver本身的getTemporaryUrl的方法。 调用driver本身方法 Storage Facade调用disk方法，获取到driver实例 driver实例满足FilesystemInterface，被FilesystemAdapter包装 FilesystemAdapter中的方法__call，接受调用 调用driver本身的方法。 总结 Facade找到Manager实例，Manager创建driver，并调用driver对应的方法。Manager同时负责扩展driver，用Adapter包装driver，来统一调用接口。</content></entry><entry><title>出现又离开</title><url>https://d-j.fun/post/thoughts/2022/0526_come_and_go/</url><categories><category>thoughts</category></categories><tags/><content type="html"> 我跟你 本应该 各自好 各自坏 各自生活的自在 毫无关联的存在 直到你 出现在 我眼中 躲不开 我也占领你的心海 充实着你的空白 为何出现在彼此的生活又离开 只留下在心里深深浅浅的表白 谁也没有想过再更改 谁也没有想过再想回来 哦 我不明白 我跟你 不应该 制造感觉 表达爱 试探未知和未来 相信那胡言一派 当天空暗下来 当周围又安静起来 当我突然梦里醒来 就等着太阳出来 为何出现在彼此的生活又离开 只留下在心里深深浅浅的表白 谁也没有想过再更改 谁也没有想过再想回来 哦 我不明白 我们紧紧相拥 头也不抬 因为不想告别 就悄然离开 不用认真的说 多舍不得你 每一个未来 都有人在 每一个未来 都有人在 那你无需感慨 我别徘徊 因为谁也没有想过再更改 谁也没有想过再想回来</content></entry><entry><title>在Kubernetes上搭建私有PyPi仓库</title><url>https://d-j.fun/post/notes/2022/05223_pypi_server_on_kubernetes/</url><categories><category>notes</category></categories><tags><tag>aws</tag></tags><content type="html"> 公共PyPi仓库上我们平时工作中经常使用的，可以解决我们大部分情况下分发包的需求。但公司的项目往往需要搭建一个私有的PyPi仓库来保证代码安全，以及防止私密信息无意泄漏。
本篇文章展示了在aws eks（即k8s）上搭建一个私有PyPi仓库的完整过程，并且编写一个demo包走完上传安装的流程。
pypiserver pypiserver库，pypi的服务器实现，通过pip install pypiserver 安装。直接pypi-server便可以启动起来，详细的参数参考 pypiserver文档, 常用参数：
-P /pypi-server/auth/.htpasswd 该参数指定的apache htpasswd file，包含用来验证的用户名密码 a update,download,list 逗号分隔，指定需要验证的动作 p 端口号，默认8080 ./packages 指定包存储位置，可以指定多个目录 pypi-server -v -P /pypi-server/auth/.htpasswd -a update,download,list ./packages
其中.htpasswd是htpasswd -b -c /pypi-server/auth/.htpasswd user pass生成
使用PyPi仓库 Demo包 创建setup.py文件
import setuptools setuptools.setup( name=&amp;#34;demo&amp;#34;, version=&amp;#34;0.0.1&amp;#34;, packages=setuptools.find_packages(), ) 另外创建一个demo.py文件
def demo(): print(&amp;#34;this is a demo&amp;#34;) 打包上传 python setup.py check 检测文件是否正确 python setup.py sdist 打包 twine upload -r kube dist/* 上传打包好的文件 其中kube可以直接使用http://user:pass@127.0.0.1:8080, 或者交互式输入密码。
也可以在cat ~/.pypirc文件中配置：
[distutils] index-servers = kube [kube] repository = http://127.0.0.1:8080 username = user password = pass 浏览器打开http://127.0.0.1:8080，便可以看到刚才上传的包文件。
Kubernetes搭建 Dockerfile FROM python:3.8-alpine RUN apk update update \ &amp;amp;&amp;amp; apk add apache2-utils \ &amp;amp;&amp;amp; apk add bash \ &amp;amp;&amp;amp; mkdir /pypi-server WORKDIR /pypi-server RUN mkdir packages &amp;amp;&amp;amp; mkdir auth RUN python3 -m pip install pypiserver passlib COPY ./docker_entry.sh /pypi-server RUN chmod +rx ./docker_entry.sh ENTRYPOINT [&amp;#34;/pypi-server/docker_entry.sh&amp;#34;] EXPOSE 8080 同目录文件docker_entry.sh
#!/bin/bash htpasswd -b -c /pypi-server/auth/.htpasswd $PYPI_USER $PYPI_PASS pypi-server -v -P /pypi-server/auth/.htpasswd -a update,download,list ./packages 执行如下步骤：
1 docker build -t pypiserver . 编译镜像 2 docker tag pypiserver:latest user/pypiserver:v0.0.1 3 docker push user/pypiserver:v0.0.1 推送镜像到官方仓库 deployment apiVersion: apps/v1 kind: Deployment metadata: name: pypiserver labels: app: pypiserver spec: // ... spec: nodeSelector: 标签对，因为使用hostPath来持久化，所以必须使用nodeSelector，指定pod所在主机 containers: - name: pypiserver image: user/pypiserver:v0.0.1 imagePullPolicy: Always env: - name: PYPI_USER value: user - name: PYPI_PASS value: pass volumeMounts: - mountPath: &amp;#39;/pypi-server/packages&amp;#39; name: pypi-packages ports: - containerPort: 8080 protocol: TCP resources: requests: cpu: 200m memory: 512Mi volumes: - name: pypi-packages hostPath: path: /data/ secrets 用户名密码可以走secrets spec，对应yaml文件
apiVersion: v1 kind: Secret metadata: name: pypisecret type: Opaque stringData: username: user password: pass 简短说明 PYPI_USER｜PYPI_PASS这两个环境变量，参考docker_entry.sh文件，是用来生成htpasswd文件 由于pod或者说容器重新启动后，上传的包就不存在了，所以必须持久化，这里为了简单是用了 hostPath，可以根据自己情况选择具体持久化类型 gitlab上搭建 gitlab本身是具有各种语言共享库的功能：
Composer Conan Go Maven NPM NuGet PyPI Generic packages 使用起来也很简单，只需要创建验证信息即可：
创建个人Token，scope设置为api 设置 ~/.pypirc: [gitlab] repository = https://gitlab.example.com/api/v4/projects/&amp;lt;project_id&amp;gt;/packages/pypi # https://gitlab.example.com/api/v4/groups/&amp;lt;group_id&amp;gt;/-/packages/pypi username = &amp;lt;your_personal_access_token_name&amp;gt; password = &amp;lt;your_personal_access_token&amp;gt; 使用twine发布 python3 -m twine upload --repository gitlab dist/* k8s搭建私有PyPi仓库
gitlab PyPi仓库</content></entry><entry><title>基于presto-go-client分析database/sql</title><url>https://d-j.fun/post/notes/2022/0522_analyze_database_sql_based_on_presto_go_client/</url><categories><category>notes</category></categories><tags/><content type="html"> presto-go-client 是一个golang的Presto客户端，基于golang database/sql通用接口实现，方便开发者快速方便使用。这也是定义接口协议的意义体现。
使用 db, err := sql.Open(&amp;#34;presto&amp;#34;, &amp;#34;http://localhost:9&amp;#34;) if err != nil { t.Fatal(err) } defer db.Close() rows, err := db.Query(&amp;#34;select 1 &amp;#34;, sql.Named(&amp;#34;X-Presto-User&amp;#34;, &amp;#34;root&amp;#34;)) if err != nil { t.Fatal(err) } var testId string for rows.Next() { err := rows.Scan(&amp;amp;testId) if err != nil { t.Fatal(err) } } 由于实现了database/sql通用数据库操作接口，使用方式和其他数据库一样。
presto实现 注册Driver sql.Register(&amp;#34;presto&amp;#34;, &amp;amp;sqldriver{}) 规范操作
sql.Open 初始化DB Struct： OpenDB不验证参数，但是不真正创建和数据库的链接。数据库链接的建立时机是在第一次真正需要建立的时候。
保存Connector：链接器，保存链接的信息，以及driver（这里是指presto，即实现了driver.Driver接口的结构体）指针 初始化openerCh：开启器channel，是一个默认1000000长度的struct{} chan 链接请求记录map初始化 可取消context初始化 sql.DB不是数据库链接，而是数据库的一种虚拟，它可以做很重要的任务：打开关闭链接；链接池管理。实现并发访问数据存储的功能。
sql.DB被设计为持久存在的，不要频繁的开启和关闭。通用的方案是为每一个数据库创建一个全局、或者方便传递的对象，保持对象存在，直到程序结束。
创建链接 链接建立是在query函数db.query调用的时候， db.conn完成这些操作：
判断数据库是否关闭（db.closed）, DB的Close函数，会赋值该开关为true 检测context是否Done，如果Done会返回ctx.Err()，这里也是QueryContext中context的实现 取db.freeConn中的最后一个链接，或者调用db.connector.Connect重新创建一个或多个(给openerCh传递信号) 链接池是一个管理空间链接，给请求复用链接的机制。database/sql的实现： 当某个goroutine需要链接的时候，先查看空间链接数组是否有可用，如果有，直接返回；如果没有，则需要判断当前开启的链接数是否达到最大值，如果是阻塞goroutine。否则创建一个链接。
链接池相关操作对应函数：
DB.conn：获取链接 driverConn.releaseConn：调用DB.PutConn释放连接 DB.PutConn：进行一些处理，调用DB.putConnDBLocked。 DB.putConnDBLocked：丢弃连接、返回连接给等待的协程或放到空闲队列。 DB.maybeOpenNewConnections：根据目前的连接请求数量和目前还能打开的连接数量判断是否发送创建连接信号给协程connectionOpener。 DB.connectionOpener：负责异步创建连接。 presto真正意义上的链接建立就在这一步，由于presto是一个http client，所以建立链接的过程很简单，只需要初始化以及验证即可：
解析dsn kerberos检测 增加了custom_client的支持 初始化http headers c := &amp;amp;Conn{ baseURL: prestoURL.Scheme + &amp;#34;://&amp;#34; + prestoURL.Host, httpClient: *httpClient, httpHeaders: make(http.Header), kerberosClient: kerberosClient, kerberosEnabled: kerberosEnabled, } 查询执行 查询执行对应函数：
QueryContext 接受sql、参数，获取数据库链接，调用Driver的对应方法查询数据 Query是QueryContext不支持context的版本 Exec 修改数据，注意如果不关心返回结果，推荐使用Exec，因为Query会保留数据库链接，直到sql.Rows关闭。可能存在维度数据，导致链接不被释放。 var testId string for rows.Next() { err := rows.Scan(&amp;amp;testId) if err != nil { t.Fatal(err) } } Presto在这里的实现，又可以被借鉴的地方。它利用NamedArgs来设置http headers。
检查args是否有特定的参数，设置header 发送post请求给/v1/statement 解析为driverRows 如果nextUri非空，迭代rows.fetch，直到获取到最后的数据 POST http://127.0.0.1:8081/v1/statement Host: 127.0.0.1:8081 User-Agent: Go-http-client/1.1 X-Presto-Catalog: hive X-Presto-User: test Accept-Encoding: gzip select 1 next &amp;amp;&amp;amp; scan next next函数结果指示下一行是否可用：true 可用，false 数据集耗尽(io.EOF)，或者中间出现错误。 注意 rows的关闭这个时候是调用房的责任，当rows开启状态的时候， 数据库链接是忙碌状态。如果忘记close，或者rows存在时间较长，是可能出现链接泄漏的情况的。
func (qr *driverRows) Next(dest []driver.Value) error { // ... if qr.columns == nil || qr.rowindex &amp;gt;= len(qr.data) { if qr.nextURI == &amp;#34;&amp;#34; { qr.err = io.EOF return qr.err } if err := qr.fetch(true); err != nil { return err } } // ... for i, v := range qr.coltype { vv, err := v.ConvertValue(qr.data[qr.rowindex][i]) // ... dest[i] = vv } qr.rowindex++ return nil } 以上是presto的next实现:
columns如果为初始化为nil，代表没有数据或执行错误 rowindex大于等于时机的数据：nextUri不为空代表有后续数据，调用fetch继续请求 正常情况挨个转化数据到dest，提供给scan使用 scan for i, sv := range rs.lastcols { err := convertAssignRows(dest[i], sv, rs) if err != nil { return fmt.Errorf(`sql: Scan error on column index %d, name %q: %w`, i, rs.rowsi.Columns()[i], err) } } 注意lastcols，就是next的参数dest。scan辅助你对结果的操作，帮你自己转换变量，迭代数据集的每一行。
// 仅需一行代码 err = db.QueryRow(&amp;#34;select name from users where id = ?&amp;#34;, 1).Scan(&amp;amp;name) Driver的意义 Driver是真正执行任务的代码，像presto-go-client，所有和presto链接建立、数据解析等操作都由该库完成。而database/sql，定义了整个数据库操作流程，以及所有相关的结构定义。presto-go-client只需要按照定义实现出来，即可以被使用。
这样的设计，使你使用多种数据库（对应多个driver），却是相同的代码，相同的流程。也方便初次使用某个数据库的时候，能够快速接入。也方便driver开发者，无需关心管理上的细节，只需要实现就好。
但是也限制了自己任务发挥的能力，有得也有失。像presto提供的是一个http协议的接口，参数、验证信息都是依赖http协议，一些附加信息也无法突破next/scan操作的限制。
presto文档
Golang database/sql与go-sql-driver源码阅读笔记
database/sql工作机制</content></entry><entry><title>如何使用openssl加密大文件</title><url>https://d-j.fun/post/technical/2022/0518_how_to_encrypt_large_file_openssl/</url><categories><category>technical</category></categories><tags><tag>Linux命令</tag></tags><content type="html"> 强大的openssl命令 openssl，一个linux命令，囊括了主要的密码算法、常用的密钥和证书封装管理功能，提供丰富应用程序测试等。只要涉及到加密、hash、证书等相关的需求，都可以使用openssl进行解决。
本文涉及到的相关只是，只是服务于本文 加密较大文件方案，只涉及到openssl的应用的很小一部分：
openssl enc 执行对称加密算法。具体支持的算法通过openssl enc -h命令查看。其中in &amp;amp; out参数分别代表输入和输出。当然也接受标准输出管道作为参数。e &amp;amp; d参数分别代表加密、解密。 openssl genpkey 生成私钥，algorithm指定具体的算法 openssl rsautl执行非对称加密 加密文件 生成大文件 mkfile -n 1g test.txt ### -rw------- 1 eight staff 1.0G May 19 01:19 test.txt 使用命令生成一个1g的大文件，用来观察加密效果、以及测试加密大文件的性能。
echo &amp;#34;\n观察加密效果，这是机密数据&amp;#34; &amp;gt;&amp;gt; test.txt 加密算法的选择 对称加密算法AES（Advanced Encryption Standard）支持128、192、256字节的密钥。AES使用简单的代数运算，使用相同的方式加密每block的数据。这种特质更适合加密大文件。但正是它的简单，造成在抗暴力破解方面，不如RSA。
非对称加密，使用一对key来加解密电子信息。RSA (Rivest–Shamir–Adleman)是我们经常使用的非对称加密，经常用于ssl、ssh等领域。它机密每block都使用不同的方式，比其他机密更安全。但是也造成在加密较大文件的时候，性能方面不理想。
结合AES和RSA 生成一个keyfile，作为AES加密的密钥文件。
openssl rand 256 &amp;gt; pwd.key AES加密test.txt，完成不到5s。
&amp;gt;&amp;gt; time openssl enc -in test.txt -out test.txt.enc -e -aes256 -k pwd.key openssl enc -in test.txt -out test.txt.enc -e -aes256 -k pwd.key 1.37s user 1.74s system 79% cpu 3.918 total AES解密test.txt.enc, 完成不到3s
&amp;gt;&amp;gt; time openssl enc -in test.txt.enc -out test.txt.decrypt -d -aes256 -k pwd.key openssl enc -in test.txt.enc -out test.txt.decrypt -d -aes256 -k pwd.key 0.51s user 1.99s system 72% cpu 3.434 total RSA相关操作
生成私钥openssl genpkey -algorithm RSA -out private_key.pem -pkeyopt rsa_keygen_bits:2048 对应公钥openssl rsa -pubout -in private_key.pem -out public_key.pem 加密密钥文件
openssl rsautl -encrypt -inkey public_key.pem -pubin -in pwd.key -out pwd.key.enc 解密密钥文件
openssl rsautl -decrypt -inkey private_key.pem -in pwd.key.enc -out pwd.key 总结 AES适合机密大文件、RSA加密方法安全。总体思路：使用RSA加密密钥文件，然后使用AES结合密钥文件加密大文件。
这样相结合大文件，首先需要RSA加密时候对应的密钥对的另一个，解开密钥文件，然后使用密钥文件再解开AES。其实仔细分析ssl协议会发现，使用了类似的方案。
总体方案：
生成公私钥 生成密钥文件 RSA加密密钥文件 AES加密大文件</content></entry><entry><title>xdebug3调试原理分析及配置迁移</title><url>https://d-j.fun/post/technical/2022/0515_how_to_debug_with_xdebug3_and_mechanism/</url><categories><category>technical</category></categories><tags/><content type="html"> xdebug3相对于2，配置方式修改了很多，在配置的时候会给出相应提示。本文使用较大篇幅分析xdebug的调试原理，以及简单的调试。针对结合PHPSTROM进行php调试也有简单涉及。
xdebug3常用配置迁移 开启方式，不再是0，1的简单设置，而是使用mode来指定xdebug处于什么模式。方便于xdebug只是加载实际需要的特性。
xdebug.mode=debug # 开启Step Debugging # 其他值off 关闭，develop 开启开发辅助，coverage 开启代码覆盖率分析，gcstats 开启垃圾收集状态统计， profile 开启分析，trace 开启函数追踪特性。 # 可以使用 xdebug_info() 查看配置 激活命令行调试export XDEBUG_CONFIG=idekey=yourname 替换为 export XDEBUG_SESSION=xdebug_is_great
自动开启调试xdebug.remote_autostart 替换为 xdebug.start_with_request
调试端口默认不再是9000，而是9003（更合理，9000往往会和fpm冲突）
调试原理 IDE集成遵循BGDP的xdebug插件，监听9000端口，监听服务端发过来的debug信息 浏览器发送带了XDEBUG_SESSION_START参数 后端php收到该请求（开启xdebug），xdebug向来源客户端9000端口发送debug请求 客户端相应这个请求，debug就建立了 后端php已经准备好后，一行行执行代码，每执行一行，就交给xdebug处理一下 xdebug处理过程，会暂停代码执行，向客户端发送代码的执行情况，等待客户端的操作 上文提到的客户端、IDE，这些指代监听9000端口这一方。而后端、服务端是指php，真正执行代码一方。 现实场景有可能是：客户端（浏览器）发起http请求，nginx接受http请求，转发给fpm（服务端），执行PHP代码。
代码分析 演示代码 &amp;lt;?php echo &amp;#39;Hello world&amp;#39;; // 1 $a = 20; // 2 $b = 40; // 3 $c = $a + $b; // 4 echo $c.&amp;#39;&amp;#39;; // 5 echo &amp;#39;Hello world&amp;#39;; // 6 方便后面分析，后面注释代表行号。
简单检测 按照调试原理，可以看出，当开启了
xdebug.mode=debug xdebug.start_with_request 执行php代码php index.php, 执行方即php, 会发送9003的请求给客户端。客户端如果依赖于ide（如phpstorm），开启右上角监听按钮即可。为了分析具体情况，可以用nc模拟监听9003端口
nc -lv 127.0.0.1 9003 # 可以参考引用中的链接，了解nc命令 这个时候在nc命令行界面便可以看到打印的init信息
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;init xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; fileuri=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; language=&amp;#34;PHP&amp;#34; xdebug:language_version=&amp;#34;7.4.16&amp;#34; protocol_version=&amp;#34;1.0&amp;#34; appid=&amp;#34;29040&amp;#34;&amp;gt;&amp;lt;engine version=&amp;#34;3.0.3&amp;#34;&amp;gt;&amp;lt;![CDATA[Xdebug]]&amp;gt;&amp;lt;/engine&amp;gt;&amp;lt;author&amp;gt;&amp;lt;![CDATA[Derick Rethans]]&amp;gt;&amp;lt;/author&amp;gt;&amp;lt;url&amp;gt;&amp;lt;![CDATA[https://xdebug.org]]&amp;gt;&amp;lt;/url&amp;gt;&amp;lt;copyright&amp;gt;&amp;lt;![CDATA[Copyright (c) 2002-2021 by Derick Rethans]]&amp;gt;&amp;lt;/copyright&amp;gt;&amp;lt;/init&amp;gt; 如果想检测具体的网络协议：
tcpdump -i eth1 -nn -A port 9003 或者wireshark
tcp.port==9003 &amp;amp;&amp;amp; tcp.flags.push == 1 交互测试 import base64 import binascii import re import socket ip_port = (&amp;#39;0.0.0.0&amp;#39;, 9003) sk = socket.socket() sk.bind(ip_port) sk.listen(10) conn, addr = sk.accept() while True: client_data = b&amp;#39;&amp;#39; data_len = 0 data = b&amp;#39;&amp;#39; while True: client_data = conn.recv(1024) if not client_data: break client_data_arr = client_data.split(b&amp;#39;\x00&amp;#39;) # 开始处为内容的长度 if not data_len: data_len = client_data_arr[0] data += client_data_arr[1] else: data += client_data_arr[0] # 最后面是以\x00结尾 if client_data_arr[len(client_data_arr) - 1] == b&amp;#39;&amp;#39;: break print(&amp;#34;[+] Raw Result: %s&amp;#34; % data) g = re.search(rb&amp;#39;&amp;lt;\!\[CDATA\[([a-z0-9=\./\+]+)\]\]&amp;gt;&amp;#39;, data, re.I) if g: data = g.group(1) try: print(&amp;#39;[+] Result: %s&amp;#39; % base64.b64decode(data).decode()) except binascii.Error: print(&amp;#39;[-] May be not string result...&amp;#39;) else: print(&amp;#39;[-] No result...&amp;#39;) data = input(&amp;#39;&amp;gt;&amp;gt; &amp;#39;) # conn.sendall(&amp;#39;eval -i 1 -- %s\x00&amp;#39; % data.encode(&amp;#39;base64&amp;#39;)) conn.sendall(data.encode(&amp;#39;utf-8&amp;#39;) + b&amp;#39;\x00&amp;#39;) 程序简单解释：
监听9003端口（如果其他配置的是其他端口，自行修改程序） '\x00'协议以该字节结尾，循环判断内容是否读取完毕 正则提取xml里的data数据 使用base64解码内容 等待用户输入 发送给服务端命令 循环以上过程 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;init xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; fileuri=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; language=&amp;#34;PHP&amp;#34; xdebug:language_version=&amp;#34;7.4.16&amp;#34; protocol_version=&amp;#34;1.0&amp;#34; appid=&amp;#34;27099&amp;#34;&amp;gt;&amp;lt;engine version=&amp;#34;3.0.3&amp;#34;&amp;gt;&amp;lt;![CDATA[Xdebug]]&amp;gt;&amp;lt;/engine&amp;gt;&amp;lt;author&amp;gt;&amp;lt;![CDATA[Derick Rethans]]&amp;gt;&amp;lt;/author&amp;gt;&amp;lt;url&amp;gt;&amp;lt;![CDATA[https://xdebug.org]]&amp;gt;&amp;lt;/url&amp;gt;&amp;lt;copyright&amp;gt;&amp;lt;![CDATA[Copyright (c) 2002-2021 by Derick Rethans]]&amp;gt;&amp;lt;/copyright&amp;gt;&amp;lt;/init&amp;gt;&amp;#39; [-] May be not string result... &amp;gt;&amp;gt; breakpoint_set -i 1 -t line -f index.php -n 3 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;response xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; command=&amp;#34;breakpoint_set&amp;#34; transaction_id=&amp;#34;1&amp;#34; id=&amp;#34;270990001&amp;#34;&amp;gt;&amp;lt;/response&amp;gt;&amp;#39; [-] No result... &amp;gt;&amp;gt; breakpoint_get -i 1 -d 270990001 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;response xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; command=&amp;#34;breakpoint_get&amp;#34; transaction_id=&amp;#34;1&amp;#34;&amp;gt;&amp;lt;breakpoint type=&amp;#34;line&amp;#34; filename=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; lineno=&amp;#34;3&amp;#34; state=&amp;#34;enabled&amp;#34; hit_count=&amp;#34;0&amp;#34; hit_value=&amp;#34;0&amp;#34; id=&amp;#34;270990001&amp;#34;&amp;gt;&amp;lt;/breakpoint&amp;gt;&amp;lt;/response&amp;gt;&amp;#39; [-] No result... &amp;gt;&amp;gt; breakpoint_list -i 1 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;response xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; command=&amp;#34;breakpoint_list&amp;#34; transaction_id=&amp;#34;1&amp;#34;&amp;gt;&amp;lt;breakpoint type=&amp;#34;line&amp;#34; filename=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; lineno=&amp;#34;3&amp;#34; state=&amp;#34;enabled&amp;#34; hit_count=&amp;#34;0&amp;#34; hit_value=&amp;#34;0&amp;#34; id=&amp;#34;270990001&amp;#34;&amp;gt;&amp;lt;/breakpoint&amp;gt;&amp;lt;/response&amp;gt;&amp;#39; [-] No result... &amp;gt;&amp;gt; breakpoint_set -i 1 -t line -f index.php -n 11 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;response xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; command=&amp;#34;breakpoint_set&amp;#34; transaction_id=&amp;#34;1&amp;#34; id=&amp;#34;270990002&amp;#34;&amp;gt;&amp;lt;/response&amp;gt;&amp;#39; [-] No result... &amp;gt;&amp;gt; breakpoint_list -i 1 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;response xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; command=&amp;#34;breakpoint_list&amp;#34; transaction_id=&amp;#34;1&amp;#34;&amp;gt;&amp;lt;breakpoint type=&amp;#34;line&amp;#34; filename=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; lineno=&amp;#34;3&amp;#34; state=&amp;#34;enabled&amp;#34; hit_count=&amp;#34;0&amp;#34; hit_value=&amp;#34;0&amp;#34; id=&amp;#34;270990001&amp;#34;&amp;gt;&amp;lt;/breakpoint&amp;gt;&amp;lt;breakpoint type=&amp;#34;line&amp;#34; filename=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; lineno=&amp;#34;11&amp;#34; state=&amp;#34;enabled&amp;#34; hit_count=&amp;#34;0&amp;#34; hit_value=&amp;#34;0&amp;#34; id=&amp;#34;270990002&amp;#34;&amp;gt;&amp;lt;/breakpoint&amp;gt;&amp;lt;/response&amp;gt;&amp;#39; [-] No result... &amp;gt;&amp;gt; run -i 1 [+] Raw Result: b&amp;#39;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;iso-8859-1&amp;#34;?&amp;gt;\n&amp;lt;response xmlns=&amp;#34;urn:debugger_protocol_v1&amp;#34; xmlns:xdebug=&amp;#34;https://xdebug.org/dbgp/xdebug&amp;#34; command=&amp;#34;run&amp;#34; transaction_id=&amp;#34;1&amp;#34; status=&amp;#34;break&amp;#34; reason=&amp;#34;ok&amp;#34;&amp;gt;&amp;lt;xdebug:message filename=&amp;#34;file:///Users/jerry/Desktop/work/phptest/index.php&amp;#34; lineno=&amp;#34;3&amp;#34;&amp;gt;&amp;lt;/xdebug:message&amp;gt;&amp;lt;/response&amp;gt;&amp;#39; 以上内容为简单演示了程序，分别测试了：设置断点、获取某个断点、列出所有断点、运行。其他演示操作可以参考引用中的文档。
总结 通过程序模拟了dbgp的过程，如果感兴趣还可以通过程序发送system('ls')的命令，感受dbgp协议的流程。关于IDE的配置，主要是在配置里找到xdebug调试端口，在这里对应php配置中的xdebug.client_port。如果修改了，重启一下ide即可。根据是否开启自动调试配置，进行不同方式的触发即可。
更详细的配置，网络上很多，本文主要在于原理分析。
引用 https://xdebug.org/docs/upgrade_guide
https://www.secpulse.com/archives/115172.html
https://wsgzao.github.io/post/nc/ nc命令
https://xdebug.org/docs/dbgp dbgp协议</content></entry><entry><title>aws cloudwatch logs insights分析业务数据</title><url>https://d-j.fun/post/technical/2022/0509_aws_cloudwatch_logs_insights_query/</url><categories><category>technical</category></categories><tags><tag>aws</tag></tags><content type="html"> 日志，监控、报表数据来源。那么日志的整个生命周期，产生、收集、存储、清洗、查询 是一个重要的问题。
不过开源的Elastic Stack，很不错的一个平台，提供了契合日志所有生命周期的工具，而且通过es本身技术实现，可以快速的针对上亿日志进行分析。
aws cloudwatch logs是熟悉aws平台的另外一个选择。cloudwatch logs结合了aws各种服务，可以实现无缝对接，而且本身一些服务默认日志存储在cloudwatch logs里。所以熟悉cloudwatch logs 是那些依赖于云服务的公司员工的一个重要技能。
关于CloudWatch Logs 日志来源和收集：服务器的自建日志（通过cloudwatch logs代理收集），aws服务产生的日志 存储： 日志流对应一个来源（比如一个服务器、或服务器上某个服务），日志组整合多个日志流。保留期、访问控制等都是在日志组层。 查询： cloudwatch logs insights提供一整套查询语法，方便使用者的分析。 众所周知，aws的基本所有接口会同时提供三种操作手段：控制台、编程方式、aws命令行。同样针对上面三步的操作。
查询CloudWatch Logs 筛选条件和模式语法 可以通过CloudWatch控制台直接在针对日志组、或着某个具体的日志流进行简单查询，如果只是查看某个RequestId所有日志，还是比较方便的。 &amp;quot;c788ad27-3e3b-4560-ac0c-87caea225078&amp;quot;。将requestid用双引号阔住，输入搜索框中，结果区就会展示该requestid对应的所有日志。
aws logs filter-log-events --log-group-name my-group [--log-stream-names LIST_OF_STREAMS_TO_SEARCH] --filter-pattern &amp;#34;c788ad27-3e3b-4560-ac0c-87caea225078&amp;#34; CloudWatch Logs Insights 如果分析日志，还是得靠CloudWatch Logs Insights强大的查询来做。
fields @timestamp, @message | parse @message &amp;#39;* - * [*] &amp;#34;* * *&amp;#34; * * &amp;#34;-&amp;#34; &amp;#34;*&amp;#34;&amp;#39; as host, identity, dateTimeString, httpVerb, url, protocol, status, bytes, useragent | stats count (*) as all, sum ( status &amp;lt; 299 ) as c_s200, sum ( status &amp;gt; 299 and status &amp;lt; 399 ) as c_s300, sum ( status &amp;gt; 399 and status &amp;lt; 499 ) as c_s400, sum ( status &amp;gt; 499 ) as c_s500 by bin (1m) 查询以管道符分割，支持函数、运算、正则等。
上面的查询分析：
fields：可以使用支持的函数和运算生成新的临时字段，供后面的查询使用。比如 status == 200 as isSuccess。功能就像sql里面的as。示例中列出日志事件中的两个字段，不做变换的情况下可以省略。 parse：从日志字段中提取新的字段。比如通过正则从@message字段中提取出各部分，生成临时字段或者最终结果展示字段。 stats by：等同于mysql中的group by，demo中 count、sum为聚合函数，5m代表将数据以五分钟为单位分割为多个桶，分别聚合不同的指标。 另外还有几个关键字比较简单：
display: 最终结果要展示的字段，类select filter: 筛选指定的条件，简单而又强大。类where limit 翻遍文档，该功能提供的api都是异步的：先提交一个查询，返回一个query_id; 然后自己轮询
func (c *Clogs) Get(group, filter string, start, end int64) (*cloudwatchlogs.GetQueryResultsOutput, error) { req, resp := c.c.StartQueryRequest(&amp;amp;cloudwatchlogs.StartQueryInput{ EndTime: aws.Int64(end), LogGroupName: aws.String(group), QueryString: aws.String(filter), StartTime: aws.Int64(start), }) err := req.Send() if err != nil { return nil, err } for { time.Sleep(30 * time.Second) results, err := c.c.GetQueryResults(&amp;amp;cloudwatchlogs.GetQueryResultsInput{QueryId: resp.QueryId}) if err != nil { return nil, err } if *results.Status != &amp;#34;Scheduled&amp;#34; &amp;amp;&amp;amp; *results.Status != &amp;#34;Running&amp;#34; { if *results.Status != &amp;#34;Complete&amp;#34; { return nil, errors.New(&amp;#34;no complete&amp;#34;) } return results, nil } } } 注意以下几点：
查询超过15分钟，会Timeout，遇到这种情况，分析以下自己的查询语句，适当缩小查询条件 查询状态如果 Scheduled | Running，都需要下次重新获取。 总结 依赖于aws云服务的公司，查看日志的需求蛮常见的。CloudWatch Logs Insights方式虽然灵活强大，但是针对简单查看某个Request的相关日志，反而不如直接筛选方便。
引用 https://docs.aws.amazon.com/zh_cn/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html 查询语法 https://docs.aws.amazon.com/zh_cn/AmazonCloudWatchLogs/latest/APIReference/Welcome.html API文档 https://docs.aws.amazon.com/sdk-for-go/api/service/cloudwatchlogs/ golang sdk文档</content></entry><entry><title>php set_time_limit函数不起作用原因解析</title><url>https://d-j.fun/post/notes/2022/0508_php_set_time_out_not_work/</url><categories><category>notes</category></categories><tags/><content type="html"> 作为phper这么多年，很多时间都花在业务、框架上，反而一些细节不经意的就抽自己一巴掌。本文解析set_time_limit配置，以及相关细节。也记录一下此次掉坑经历，给自己以后指一个方向。
起因 服务器某个接口相应时间长达100s，而且报nginx 502错误。检查发现php max_execution_time使用的默认值30s。错误分析：502 gateway错误，可以定位到是php脚本处理太慢造成的。但是让人怀疑的是为什么30s脚本不停止。
解析 官方解释 The set_time_limit() function and the configuration directive max_execution_time only affect the execution time of the script itself. Any time spent on activity that happens outside the execution of the script such as system calls using system(), stream operations, database queries, etc. is not included when determining the maximum time that the script has been running. This is not true on Windows where the measured time is real. 翻阅官方文档得到答案：该配置项仅仅代表脚本本身的执行时间，而不包括系统调用、流操作、数据库查询所占用的时间（即不计算 sleep,file_get_contents,shell_exec,mysql_query等花费的时间）。
起因中提到的问题就找到原因了：脚本本身查询mysql耗费了太久时间，导致达到nginx proxy_read_timeout 100时间限制。nginx在发现proxy即fpm没有在规定时间内返回结果，就直接返回调用方502错误。
自我验证 &amp;lt;?php error_reporting(0); ini_set(&amp;#39;display_errors&amp;#39;, &amp;#39;off&amp;#39;); // set_error_handler 不能捕获致命错误 register_shutdown_function(function () { echo sprintf(&amp;#34;脚本结束时间%f\n&amp;#34;, microtime(true)); }); echo sprintf(&amp;#34;脚本开始时间%f\n&amp;#34;, microtime(true)); for($i=0;$i&amp;lt;100000000;$i++){ sha1(time()); } echo sprintf(&amp;#34;第一次循环结束时间%f\n&amp;#34;, microtime(true)); set_time_limit(10); $i = 0; while ($i &amp;lt;= 10) { echo &amp;#34;i=$i &amp;#34;; sleep(2); $i++; } $end = microtime(true); var_dump(getrusage()); echo sprintf(&amp;#34;\n第二次循环结束时间%f\n&amp;#34;, microtime(true)); while (true) { sha1(time()); } echo sprintf(&amp;#34;\n第三次循环结束时间%f\n&amp;#34;, microtime(true)); // output //脚本开始时间1651993104.293944 //第一次循环结束时间1651993191.067107 //i=0 i=1 i=2 i=3 i=4 i=5 i=6 i=7 i=8 i=9 i=10 //第二次循环结束时间1651993213.096094 //脚本结束时间1651993223.126825 第一次循环占用时间 86.77s (时间1) 第二次循环占用时间 22.02s (时间2) 第三次循环占用时间 10.03s (时间3) 脚本解析：
时间1是在set_time_limit执行前的脚本执行时间，说明set_time_limit执行的时候，时间计数器从0重新计数 时间2是因为sleep了11次，每次2s。说明循环本身只是占用了0.02s 时间3是set_time_limit开始到脚本Fatal Error退出执行之间的时间。虽然第二次循环占用了22s，但是sleep不被计数。 设置真实执行时间 &amp;lt;?php echo sprintf(&amp;#34;脚本开始时间%f\n&amp;#34;, microtime(true)); pcntl_async_signals(1); pcntl_signal(SIGALRM, function () { echo sprintf(&amp;#34;脚本结束时间%f\n&amp;#34;, microtime(true)); exit(&amp;#39;Stop it!&amp;#39;); }); pcntl_alarm(3); $i = 0; while (true) { $i++; sha1(time()); echo &amp;#34;i = {$i}\n&amp;#34;; } echo sprintf(&amp;#34;脚本结束时间2%f\n&amp;#34;, microtime(true)); // output 脚本开始时间1651994735.305631 i=33万次... 脚本结束时间1651994738.307060 Stop it! 或者使用fork调用，父进程监控子进程运行。
$pid=pcntl_fork(); if ($pid) { while (true) { shell_exec(&amp;#39;sleep 10&amp;amp;&amp;#39;); } } else { sleep(5); posix_kill(posix_getppid(),SIGKILL); } 如果是CLI脚本，有更多解决方案：
timeout 5 /usr/bin/php -q /path/to/script 总结 不建议使用set_time_limit(0), 因为脚本会一直执行下去，影响服务器负载 脚本默认max_execution_time为0，即会一直执行下去，建议设置该配置，因为脚本会永久占用进程。 set_time_limit 会重置时间计数。比如在脚本已经运行20s的时候调用set_time_limit(10),那么脚本执行时间为30s。如果运行一个耗时任务的时候，一般放在脚本第一行。 sleep,file_get_contents,shell_exec,mysql_query这些函数包含在设置的时限内，所以这些函数本身执行时间应该自己考虑在内，不要让时间浪费在没必要的事情上。 set_time_limit 不能使用在安全模式下。set_time_limit() [function.set-time-limit]: Cannot set time limit in safe mode</content></entry><entry><title>上海在《这个春天》郝景芳</title><url>https://d-j.fun/post/thoughts/2022/0508_this_spring/</url><categories><category>thoughts</category></categories><tags/><content type="html"> 被疫情阻隔的春天、岁月和一去不复返的过去、我们
这个春天
我们看见悲伤的形状
悲伤被记忆炖煮
在空寂的盘中释放清香
这个春天
花朵盛放
寂寥的街景无人观赏
花的命运与花椰菜一样
因一道禁令，抵达不了人的欲望
这个春天
我们无比怀念远方
我们微笑着回忆那年在路上
星空下点篝火，闻林间青草香
我们一直微笑着遐想
在饥饿中遐想
这个春天
我们见到了死亡的模样
哭声在窗外回荡
刺在心上，堵住倾诉的愿望
那粒灰尘什么时候落到自己头上
物伤其类，目睹神伤
生命随河水流淌
岂知愤怒会不会被时间埋葬
这个春天
灵魂要压抑对自由的渴望
良心要回避对正义的主张
智能机器在寻访
人类沟通在躲藏
善良的人呈现出暴力倾向
软弱的人承担抗争的坚强
黑市肆意疯长
人们拼死奔忙
只想寻找活下去的方向
这个春天
有人撒谎
有人刺破他人撒谎
有人禁止刺破他人撒谎
有人见证禁止刺破他人撒谎
这个春天
我们识得人生的方向
只愿在饥饿时留一点善良
在黑暗时留一点光
那些在疲惫困顿中保持慈悲的人们啊
我愿在远方的路上为你们歌唱
愿大地记住你们的顽强
愿风记住你们的悲伤</content></entry><entry><title>使用jenkins pipeline部署Gcloud Function</title><url>https://d-j.fun/post/notes/2022/0506_jenkins_pipeline_deploy_gcloud_function/</url><categories><category>notes</category></categories><tags/><content type="html"> Google Cloud Function、aws lambda都是类似的无服务器服务，一种轻量级计算解决方案，通过相应平台封装的对应事件，返回响应。无需管理服务器、并且可以根据负载量自动扩缩容，这些特点特别方便我们一些高负载的需求。
但是代码部署方式上，和在服务器上自主搭建服务是有差别的：gcf接受Cloud Source Repositories（google的代码库平台）、zip文件；aws lambda 接受编译好的二进制文件的压缩包。不过aws 和 gcloud 都提供了强大的命令行工具，配合jenkins部署是一个不错的选择。由于gcloud、aws机制类似，本文以gcloud为例。
Google Cloud Function 部署 代码载体选择 google cloud function支持四种：
内嵌编辑器： 只适合一些简单的测试 zip文件上传：将zip打包比较适合jenkins，jenkins对shell脚本支持的比较好，但是gcloud命令没有看到接受文件上传的选项。 cloud storage上的zip：google cloud storage对应aws的s3，将代码压缩好上传到这里还可以备份，是比较好的选择 Cloud Source Repositories：考虑到一般公司都选择自建的gitlab仓库，需要做一层同步。 通过比较几种代码载体，第三种是适合博主的方式，具体选择哪种，视你的具体场景选择。
gcloud sdk安装 安装教程见 Google CLi安装 。一般服务器linux操作系统错不了，简单整理官方文档步骤如下:
1 2 3 4 5 6 7 8 9 # 下载google cloud sdk压缩包 curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-377.0.0-linux-x86_64.tar.gz # 解压 tar -xf google-cloud-sdk-377.0.0-linux-x86.tar.gz # 执行安装sh脚本 ./google-cloud-sdk/install.sh # 由于要把代码上传到cloud storage，用到alpha组件 gcloud components install beta #接下来不要执行gcloud init，jenkins部署提供了secret file认证文件的管理，为了安全。 以上操作是在jenkins同台机器上执行。
gcloud sdk认证 首先判断是否已认证：gcloud auth list。该命令会列出已认证的账号，以及活跃账号。 google iam提供了几种认证方式，因为要在jenkins pipeline里使用，最好选择gcloud auth activate-service-account。当然也可以选择直接在jenkins机器jenkins用户下直接执行gcloud init。 即使gcloud auth activate-service-account该种方式认证，gcloud也会将私钥的副本存储在$HOME/.config/gcloud目录下面。如果要可靠的存储gcloud身份验证信息，在运行完pipeline之后，清楚一下本地缓存的密钥文件rm -rf $HOME/.config/gcloud。
另外建议创建权限足够但不多余的专门用户，服务于jenkins。权限请选择：Cloud Functions Admin、Storage Admin。 jenkins pipeline部署 pipeline介绍 jenkins pipeline 流水线是用户定义的一个cd模型，通过代码定义项目的整个构建过程，支持各种组件，灵活而强大。类似的有github runner、bitbucket pipeline以及比较通用的github actions。
pipeline { agent any stages { stage(&amp;#39;Build&amp;#39;) { steps { sh &amp;#39;make&amp;#39; } } stage(&amp;#39;Test&amp;#39;){ steps { sh &amp;#39;make check&amp;#39; junit &amp;#39;reports/**/*.xml&amp;#39; } } stage(&amp;#39;Deploy&amp;#39;) { steps { sh &amp;#39;make publish&amp;#39; } } } } 简单的语法定义将构建过程分成步骤stage，同时支持环境变量定义，同时jenkins还提供了pipeline-syntax片段生成器。详细参考Jenkins Pipeline文档。
添加密钥文件 在jenkins系统管理-全局凭据中，添加密钥，选择 secret file。具体可参考 []
jenkins pipeline部署Gcloud Function pipeline示例 pipeline { agent any stages { stage(&amp;#39;克隆&amp;#39;) { when { branch &amp;#39;main&amp;#39; } steps { dir(path: &amp;#34;./&amp;#34;) { checkout([$class: &amp;#39;GitSCM&amp;#39;, branches: [[name: &amp;#39;*/master&amp;#39;]], doGenerateSubmoduleConfigurations: false, userRemoteConfigs: [[credentialsId: &amp;#34;仓库git凭证&amp;#34;, url: &amp;#39;仓库地址&amp;#39;]]]) } } } stage(&amp;#39;上线&amp;#39;) { when { branch &amp;#39;main&amp;#39; } steps { withCredentials([file(credentialsId: &amp;#39;gcloud secret file id&amp;#39;, variable: &amp;#39;GCP_FILE&amp;#39;)]) { sh &amp;#39;git archive -o /tmp/code.zip HEAD&amp;#39; sh &amp;#34;gcloud auth activate-service-account 账户名称 --key-file=&amp;#39;${GCP_FILE}&amp;#39;&amp;#34; sh &amp;#39;gcloud alpha storage cp /tmp/code.zip gs地址&amp;#39; sh &amp;#39;gcloud functions deploy 函数名 --source gs地址&amp;#39; } } } stage(&amp;#39;测试&amp;#39;) { steps { sh &amp;#39;curl -vvv 链接&amp;#39; } } } } 触发构建，可以根据自己需要设置，例子中是main分支有更新。还可以选择手工点击构建。
可能遇到的问题 gcloud sdk not found类似问题：安装gcloud cli必须安装在jenkins所在机器 User does not have the 'iam.serviceAccounts.actAs' permission on *@appspot.gserviceaccount.com required to create the function. You can fix this by running gcloud iam service-accounts add-iam-policy-binding *@appspot.gserviceaccount.com --member=user: --role=roles/iam.serviceAccountUser&amp;quot;,详见 官方解释 ：是因为创建用户和部署用户不同，解决办法为 gcloud iam service-accounts add-iam-policy-binding 创建function用户 --member=serviceAccount:serviceaccount用户 --role=roles/iam.serviceAccountUser 总结 jenkins pipeline是一个简单而又强大的cd工具，可以从平时复杂冗余的工作中解放出来。由于对shell及jenkins本身强大的插件机制，可扩展的地方很多，本文只是拿一个具体的任务举例。目前比较可惜的是pipeline类似的功能都是在具体的平台上，没有一个更宽泛的概念，期待。。。
引用 https://cloud.google.com/sdk/gcloud/reference/functions/deploy gcloud sdk function文档 https://tech.ray247k.com/blog/202204-jenkins-cicd-3-push-docker-image-to-gcr/ Jenkins 打包 Docker image 並推送到 GCR</content></entry><entry><title>curl 关于服务时间性能的指标探究及应用</title><url>https://d-j.fun/post/notes/2022/0501_benchmark_server_latency_with_curl/</url><categories><category>notes</category></categories><tags><tag>Linux命令</tag></tags><content type="html"> 作为一个服务端开发，强烈意愿需要一个性能检测工具，而时间是性能一个重要的指标。而curl 请求输出可以根据自己需要设置（time_namelookup、time_connect、time_appconnect、time_pretransfer、time_starttransfer、time_total）时间相关的输出。但是搜索了google、baidu不止一天两天，得到的答案都是man curl，而没有一个更精准、容易理解的答案。最终无意中搜索到&amp;lt;引用&amp;gt;的文章，茅塞顿开，建议读到本篇文章的都耐心读完。
预备知识 curl标准化输出 在一个请求结束时，curl会根据-w，&amp;ndash;write-out 选项打印出来定制化信息到标准输出。format 包含有占位符的字符串，curl会替换占位符为预定义的变量的值。
比如 HTTP状态码：%{http_code} 会被替换为 HTTP状态吗: 200
时间指标官方解释 时间指标的单位都是秒，计时开始都是curl请求开始时间，也就是dns开始查询那一刻的时间。
time_namelookup：开始到dns查询完成花费时间 time_connect：开始到tcp三次握手完成花费时间 time_appconnect：开始到ssl握手时间完成花费时间 time_pretransfer: 开始到文件传输即将开始花费时间 time_starttransfer: 从开始到第一个字节即将被传输，包含time_pretransfer和服务器计算结果所需时间 time_total 整个操作所有花费时间 理解重点 一个容易被忽略的前提，curl作为一个客户端工具，计算所有时间的前提都代表着网路传输的客户端。理解每个时间，必须先提醒自己这个前提。
探究过程 请求例子 /usr/local/opt/curl/bin/curl -L -w &amp;#39;@curl.txt&amp;#39; &amp;#39;localhost:8080/a.php&amp;#39; time_namelookup: 0.002783 time_connect: 0.002928 time_appconnect: 0.000000 time_redirect: 2.104259 time_pretransfer: 0.002981 time_starttransfer: 6.177934 ---------- time_total: 6.178134 例子详情：
// a.php &amp;lt;?php sleep(2); header(&amp;#34;location:./b.php&amp;#34;); // b.php &amp;lt;?php sleep(4); time_namelookup指标 这个很好理解，dns查询时间，即curl访问某个域名的时候，需要先从dns服务器以下该域名对应的ip。这个过程一般会很快，是因为服务器在首次获取到ip的时候，会缓存结果一段时间。我在本地测试/etc/hosts解析的域名，时间保持在2～3ms左右。
time_connect指标 网络建立socket需要经历三次握手，该指标的值就是开始到建立socket成功的时间。time_connect-time_namelookup即curl和服务器建立socket所花费的时间，对应上面的例子花费了0.145ms。测试了baidu，该指标为21ms。
time_appconnect指标 真正的传输建立完socket便可以，比如http便是直接在tcp协议上传输内容。但是https为了网络内容的安全会在tcp上再次进行ssl层的建立，该阶段百度测试120ms。所以该指标也是一个很重要的查询整体性能的因子。上面的例子由于是http，故该指标值为0。
time_redirect指标 从上例子中可以看出，该指标是截止点在于跳转到b之前的瞬间。由于a文件在跳转之前先等待了2s，所以curl接收到301请求之后，由于-L（follow redirects），会立马请求b.php，但是b.php的返回是4s之后，所以该时间点，应该是接收到301之后，再次请求服务端的瞬间。
这里就牵扯到一个问题：如果header location 是其他网站，是不是要重新计算namelookup的时间，以及建立链接的时间。
// a.php &amp;lt;?php sleep(2); header(&amp;#34;location:https://www.baidu.com&amp;#34;); time_namelookup: 0.090075 time_connect: 0.158963 time_appconnect: 0.214078 time_redirect: 2.412030 time_pretransfer: 0.308881 time_starttransfer: 2.570669 ---------- time_total: 2.577325 可以看到time_namelookup、 time_connect、time_appconnect都有较大的变化，如果单独请求百度得到的三个值也会小于上面三个值。所以三个指标如果包含跳转，应该是跳转前后两次的对应加和。
该指标指最后一个请求开始的瞬间，只考虑整个链条的最后一次请求。
最困惑的time_pretransfer指标 从上面的例子可以发现该指标会比time_appconnect（https）或time_connect（http）多几十微秒，如果是跳转会多点，但是相对于网络来回来说，这个时间太小。所以有的文档说，该指标只是为了和connect概念上做区分。但是从细微的时间上的差别来看，足够cpu做很多事情，所以它表示的应该是，在connect之后处理了一些协议相关的初始化操作，然后将数据放到网卡之前的瞬间。
通俗的说，该指标结束点在于开始往服务器发送真正的http、https请求的瞬间。
time_starttransfer和time_total指标 这两个指标应该是比较好理解的。time_starttransfer 对应TTFB，即curl收到服务端传来的第一个字节的瞬间。time_total整个curl操作周期的总时间。
指标应用 dns解析快慢，直接使用time_namelookup 链接创建时间，根据http\https, 使用time_connect\time_appconnect - 直接使用time_namelookup 服务端处理时间，time_starttransfer - time_pretransfer 内容下载时间，time_total - time_starttransfer 总结 curl的几个时间指标真实反应一次请求的各个阶段，对于服务时间性能方面的测试是一个很大的助力。关于本文，主要针对无法理解curl man的解释，做了各个方面的探究。这些探究都是针对实际操作而得出的结论，可能无法真实反应curl本身源代码方面的设计。
不过针对平时的应用，参考&amp;lt;指标应用&amp;gt;小节，完全可以满足平时所用。如果针对某个具体的指标有疑问，可以深入到具体的指标实验中做对比。
引用 https://speedtestdemon.com/a-guide-to-curls-performance-metrics-how-to-analyze-a-speed-test-result/</content></entry><entry><title>Github Pages最佳实践, 基于Github Actions</title><url>https://d-j.fun/post/notes/2022/0501_github_pages_best_practices/</url><categories><category>notes</category></categories><tags><tag>Github</tag></tags><content type="html"> 搭建本博客使用到的技术是hugo结合github page，详见hugo自建博客。博客中可以看到详细过程：将hugo写作环境推到github main分支，通过github action构建到gh-pages分支。这是目前见到的大部分方案，也有通过在其他仓库（gitee）将最终结果推送到github上的。
最佳实践 个人觉得最佳的方案，应该隐藏写作环境，即hugo最终生成静态文件依赖的模板、md文件等。否则复制一个网站的成本就太小了，有心的人只需要下载你的写作环境，本地重新build以下，即可完全仿造你的整个流程。当然编译后的静态文件总归要暴露出去，但是后续更新、批量修改都增加了仿冒的成本。
针对本博客的实现方案，最佳实践应该为 main分支隐藏，gh-pages分支继续保留。
实现方案 构想过集中方案，可以根据自己情况实施：
自己有服务器的，可使用的方案很多，写作环境保留在自己服务器即可，静态文件可以存放服务器，或者推送到github pages 建立两个Github仓库（注意创建顺序），写作环境保存在私有仓库，推送到另外一个公开仓库里面 类似2，不过写作环境放在自己搭建的仓库更安全，或者国内gitee、国外aws gitcommit 我选择第二种方案测试了一下
创建私有仓库 由于Github 二级域名默认在账号级别创建的第一个仓库为根目录，具体实施应该为：
静态文件推送到账号下第一个创建的仓库 写作环境推送到账号下除第一个创建仓库以外的仓库 我的做法：将第一个仓库的内容删除，然后本地git remote add origin 第二个仓库地址
构建实现 peaceiris/actions-gh-pages 该该组件是编译好的静态文件推送到Github Pages，集成于Github Actions。详细见 hugo自建博客 Github Actions yaml文件。
- name: Deploy # 部署 uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.PERSONAL_TOKEN }} publish_dir: ./public cname: www.d-j.fun external_repository: micywin/hugo-dj 注意yaml和原文章的区别，由于原文章是将构建好的静态文件推送到当前仓库的gh-pages分支，直接使用Github Actions初始化的Github_TOKEN即可，但是如果跨仓库，甚至于不通的仓库提供商，那么这里就要设置为对应的token。由于博主使用的是github的另外一个仓库，使用personal_token即满足需求。
按照上图设置好secrect之后，注意external_repository，这里是设置相对于当前仓库的另外一个仓库。
这样设置好之后，重新推送一下写作环境的代码到第二个仓库，那么没有问题情况下，第一个仓库的gp-pages分支会出现最新一版的静态文件。
拓展内容 关于peaceiris/actions-gh-pages该组件还有更多的配置选项，可以根据自己需要去配置，个人觉得比较有用的：
设置full_commit_message, 让每次更新可以看到提交的相关信息 如果不想部署的时候影响到在线阅读体验，可以定时在半夜部署 等，可以根据自己情况去配置。博主的Deploy的完整配置：
- name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.PERSONAL_TOKEN }} publish_dir: ./public cname: www.d-j.fun external_repository: micywin/hugo-dj full_commit_message: ${{ github.event.head_commit.message }} 总结 为了写作体验，和后续可能的问题，应该提前做好各种规划。比如本文提到的写作环境隐藏、自动给图片添加水印、还有目录的规划、文章分类的划分等。</content></entry><entry><title>使用hugo在github上搭建独立博客</title><url>https://d-j.fun/post/technical/2022/0426_hugo_hosted_on_github/</url><categories><category>technical</category></categories><tags><tag>Github</tag><tag>Hugo</tag></tags><content type="html"> hugo golang编写的静态化网站构建工具，速度、灵活是两个标榜的特点。选择该工具的原因：有自己喜欢的模版、方便的自定义、快速的调试，最关键是可以git版本化管理内容，不用依托于mysql，这是最关键的原因。
github pages更是提供了免费的托管，同时github actions提供自动化编译，搭配起来是完美。
纵览搭建过程 Hugo 在本地初始化git仓库，在该仓库中搭建hugo环境，主要是选择自己喜欢的模板 Hugo 主题 。接下来比较耗费时间的是，根据自己需要修改模板：比如title、description，还有一些样式，很多没有定义在配置里，就需要自己在layouts中找到对应的文件进行修改，不过hugo的文件结构比较清晰，有过网站开发经验的很容易找到规律。
Github 本地准备完毕后便可以将整个hugo环境推到github，然后利用github actions自动化构建，便完成基础搭建。 hugo官方提供的有github actions yml文件，可以根据自己需要改动。
一般的流程是：
拉取代码 hugo编译 代码推送到gh-pages分支 最终在github仓库的设置里，将pages分支设置为gh-pages，便可以通过【github username】.github.io网址，看到自己的博客雏形了。
详细搭建过程 本小节除了给出一些必要的安装步骤，还会推荐一些工具搭配，除了有利于搭建过程、对以后博客坚持写作也有帮助。同时一些安装过程中踩到的坑，也会在具体步骤中标注。
Hugo环境 官网给出了无比详细的、各个平台的安装步骤 Hugo 安装 , 直接选择自己的操作系统，一步步安装即可。由于博主开发机是mac pro，直接一步到位 brew install hugo
打开 terminal (推荐安装iTerm2), 输入hugo version, 如果输出hugo版本，代表安装成功，并正确配置了执行路径。如果提示找不到命令，原因可能是 hugo执行程序不在环境变量PATH中，将程序放到PATH路径中，一般是bin、/user/bin等，或者执行export PATH=&amp;quot;$PATH:hugo安装路径&amp;quot;，再次执行hugo version。一般的问题都出在这里，如果不符合自己的情况，可以再仔细阅读官方安装文档，或者通过评论联系博主。
新建网站：hugo new site [eight]。该命令会在执行命令的当前路径，新建eight文件夹，目录中比较重要的有themes目录, config.toml。执行完命令，用一款编辑器打开目录，熟悉一下目录结构，毕竟以后写博客都要面对这些目录。推荐安装sublime，博主开发环境都选择idea，随意选择了goland。无论选择什么编辑器，方便的文件管理、目录结构、markdown编辑预览功能是必须具备的。工具一定要选择一个适合自己，功能方便的，涉及到自己的写作体验。
Hugo主题 hugo主题选择，个人喜好问题，不过不建议花太多时间在这上面，毕竟搭建博客是为了记录、分享内容（虽然博主纠结了好久，最终选择了next）。
hugo主题安装三种选择，不同的选择，各有优劣，视自己具体情况而定：
git submodules: git submodule add 主题仓库地址 themes/主题名称，该方法适合于以后完全不会自己修改模板的人，好处是如果模板主题作者修改了模板，还可以随时更新到最新。但是如果想自定制一些功能，就得去原作者仓库提交pr。 将文件复制到themes目录：在其他目录下载完themes文件，将文件夹复制到themes目录下，随着你的git仓库一块提交，相当于在你的仓库里增加文件内容。这样你可以随意修改模板、样式，但是相对于根目录来说，themes有很多部分是重合的，如果是极度洁癖慎用。 将模板对应的文件夹，覆盖根目录对应文件：该方法具有第二种方法的随意修改的有点，而且文件也不会出现冗余，博主选择该方法。 执行hugo server，在命令提示中可以看到 localhost:1313 (如果你在另外一个地方执行过了，可能是其他端口)，将该地址复制到浏览器地址栏，点击访问，便可以实时预览自己的博客。如果你修改了博客中的模板、样式、文章等，保存后便可以在这个地址看到。
这个时候，便可以修改logo、博客名称、博客描述，最好加一篇文章方便调试。
Github Pages部署 上面步骤好了之后，便可以部署github pages了。注意一点：一个github账号，只有一个github.io的域名（【github username】.github.io），如果不是规划该账号下，多个项目对应一个域名，那么建议新建一个github账号。
假设你的账号用户名 eight（小八），那么可以新建一个public仓库eight.github.io (这样命名，github会默认开启pages功能，不过不强求)，copy仓库地址。然后在本地仓库执行git remote add origin 仓库地址，然后将代码推送到GitHub仓库。有一个点，github主分支默认是main，本地一般都是master。具体用哪个自己偏好决定。
在项目根目录添加.github/workflows/gh-pages.yml文件：
name: github pages # 任务名称 on: push: branches: - main # 触发分支 jobs: deploy: runs-on: ubuntu-20.04 # 任务执行环境 steps: # 每个步骤：name 步骤名称，uses 使用组件，with 参数 - name: Check out repository code # 下载代码 uses: actions/checkout@v2 with: submodules: true - name: Setup Hugo # 下载hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: &amp;#39;latest&amp;#39; ## extended: true - name: ls # 最好加这一步，要不然报错都不知道为啥，查看工作空间文件 run: ls ${{ github.workspace }}/themes/hugo-theme-next2/ - name: Build # 构建 run: hugo --minify - name: Deploy # 部署 uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public cname: www.d-j.fun 推送到github之后，会自动按照这个yaml文件的脚本执行，注意分支名字，如果不对，该workflows不会执行。如果没有执行成功，点击github 仓库的actions按钮，然后找到具体的action，点开可以查看详细log记录。成功后仓库会多一个gh-pages分支。
特别需要注意：cname文件，如果要使用自定义的域名，cname参数会使 peaceiris/actions-gh-pages@v3 添加一个cname，cname文件如果缺失，会造成github仓库设置里面的自定义域名丢失lost。。。
后续操作 这个时候访问eight.github.io，便可以看到自己的博客。 不同的模板需要的配置不一样，还需要稍微的微调。如果想自定义域名，点击github仓库的设置，找到pages，在custom domain填入自己的域名。有个先提条件，需要将域名cname到eight.github.io。
Hugo自建博客总结 整个过程步骤不多，但是小细节很多。比较耗费时间的是下载主题总归会有需要修改的地方，这个比较耗费时间。还有应该着重在内容上，不要太纠结于一些界面上的瑕疵。一定要选择自己满意的编辑器，特别是修改layouts布局文件的时候，以及发布文章。否则会被一些格式上面的问题困扰。
感谢 本博客搭建参考了 兰陵子 的搭建过程，也参考了 凡梦星尘 的优化笔记 。</content></entry></search>